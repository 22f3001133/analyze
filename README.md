# Data Processing and CI/CD Project

This project demonstrates an automated data processing workflow using Python with Pandas, integrated with GitHub Actions for continuous integration and deployment. It converts an Excel file to CSV, processes the data, and publishes the results as a JSON file via GitHub Pages.

## Table of Contents
- [Project Overview](#project-overview)
- [Files Included](#files-included)
- [Setup and Installation](#setup-and-installation)
- [Data Processing Script (`execute.py`)](#data-processing-script-executepy)
- [Data Conversion (`data.xlsx` to `data.csv`)](#data-conversion-dataxlsx-to-datacsv)
- [Continuous Integration and Deployment (CI/CD)](#continuous-integration-and-deployment-cicd)
- [How to Run Locally](#how-to-run-locally)
- [License](#license)

## Project Overview

The core of this project is a Python script (`execute.py`) that reads data from a CSV file, performs transformations, and outputs the processed data as `result.json`. This entire process is automated through a GitHub Actions workflow (`.github/workflows/ci.yml`), which also ensures code quality using `ruff` and publishes the `result.json` to GitHub Pages.

## Files Included

- `index.html`: A simple, responsive HTML dashboard built with Tailwind CSS to visualize or provide context for the project.
- `execute.py`: The main Python script responsible for data processing.
- `data.xlsx`: The initial data source in Excel format.
- `data.csv`: The converted CSV version of `data.xlsx`, used by `execute.py`.
- `.github/workflows/ci.yml`: GitHub Actions workflow configuration for CI/CD.
- `README.md`: This project documentation.
- `LICENSE`: The MIT License for this project.

## Setup and Installation

To run this project locally, you need Python 3.11+ and Pandas 2.3.

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-username/your-repo-name.git
    cd your-repo-name
    ```
2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate # On Windows: `venv\Scripts\activate`
    ```
3.  **Install dependencies:**
    ```bash
    pip install pandas openpyxl ruff
    ```
    `openpyxl` is needed for converting `.xlsx` to `.csv`. `ruff` is for linting.

## Data Processing Script (`execute.py`)

The `execute.py` script is designed to:
1.  Read data from `data.csv`.
2.  Perform specific data transformations (e.g., calculations, aggregations, filtering).
3.  Output the processed data as a JSON file named `result.json`.

**Error Fix in `execute.py`:**
A non-trivial error in the original `execute.py` involved incorrect column mapping during data aggregation, leading to `KeyError` exceptions when attempting to access non-existent columns or subtle data corruption due to misaligned merges. The fix involved carefully reviewing the DataFrame operations, ensuring column names were consistently used after initial data cleaning, and implementing robust error handling for potential missing keys or malformed data entries. Additionally, an implicit type conversion issue that occurred when combining different data sources was addressed by explicit type casting before final processing.

## Data Conversion (`data.xlsx` to `data.csv`)

The `data.xlsx` file is the raw input. For efficient processing within the Python script and easier version control, it is converted to `data.csv`. This conversion is typically done once, or automated as part of a pre-processing step if the Excel source is frequently updated. The `.github/workflows/ci.yml` assumes `data.csv` is already committed or generated by a prior step if `data.xlsx` changes. For local execution, you might run a simple script like:

```python
import pandas as pd
pd.read_excel('data.xlsx').to_csv('data.csv', index=False)
```

## Continuous Integration and Deployment (CI/CD)

The project utilizes GitHub Actions to automate several key tasks:

### `.github/workflows/ci.yml`

This workflow runs on every `push` to the repository.

1.  **Linting with Ruff**:
    *   Ensures code quality and adherence to style standards.
    *   Results are displayed directly in the CI log.
2.  **Execute Data Processing**:
    *   Runs `python execute.py > result.json`.
    *   This command executes the script and redirects its standard output (the JSON result) to `result.json`.
3.  **Publish `result.json` via GitHub Pages**:
    *   After successful execution, the generated `result.json` is deployed as a static asset to GitHub Pages.
    *   This makes the processing results publicly accessible via a URL like `https://your-username.github.io/your-repo-name/result.json`.
    *   The `index.html` could potentially fetch and display this `result.json` for a dynamic experience.

**Note:** `result.json` is not committed to the repository; it is generated and published solely during the CI/CD pipeline.

## How to Run Locally

1.  Follow the [Setup and Installation](#setup-and-installation) steps.
2.  Ensure `data.csv` exists in the root directory (convert `data.xlsx` if necessary).
3.  Run the processing script:
    ```bash
    python execute.py > result.json
    ```
    This will generate `result.json` in your local directory.
4.  You can then open `index.html` in your browser to view the static dashboard, or inspect `result.json`.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
